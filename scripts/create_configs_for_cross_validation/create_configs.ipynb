{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Split MIBiG compounds into 5 groups for cross-validation based on BigScape families.",
   "id": "35f84ba0fa33b30e"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-09T17:27:27.944048Z",
     "start_time": "2025-06-09T17:27:27.913950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from math import ceil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "nerpa_dir = Path('/home/ilianolhin/git/nerpa2')\n",
    "\n",
    "mibig_bgcs_table = pd.read_csv(nerpa_dir / 'scripts/build_mibig_info_table/mibig_bgcs_info.tsv', sep='\\t')\n",
    "mibig_compounds_approved = mibig_bgcs_table[mibig_bgcs_table[\"in_approved_matches\"] == True].copy()\n",
    "\n",
    "if mibig_compounds_approved[\"bigscape_families\"].isna().sum() > 0:\n",
    "    print('Warning! Missing bigscape_families values present.')\n",
    "\n",
    "# Aggregate BGCs by BigScape family using groupby\n",
    "family_to_bgcs = mibig_compounds_approved.groupby(\"bigscape_families\")[\"bgc_id\"].apply(list).to_dict()\n",
    "\n",
    "n_groups = 5  # Number of groups to split the families into\n",
    "total_bgcs = sum(len(bgcs) for bgcs in family_to_bgcs.values())\n",
    "target_group_size = ceil(total_bgcs / n_groups)\n",
    "\n",
    "family_iter = iter(family_to_bgcs.items())\n",
    "family_to_sample_group = {}\n",
    "\n",
    "for group_idx in range(n_groups):\n",
    "    group_size = 0\n",
    "    while group_size < target_group_size and (family := next(family_iter, None)) is not None:\n",
    "        family_name, bgcs = family\n",
    "        family_to_sample_group[family_name] = group_idx\n",
    "        group_size += len(bgcs)\n",
    "\n",
    "# q: assert that all families are assigned to a group\n",
    "assert len(family_to_sample_group) == len(family_to_bgcs), \"Not all families are assigned to a group\"\n",
    "\n",
    "# Assign sample group to each row\n",
    "mibig_compounds_approved[\"sample_group\"] = (mibig_compounds_approved[\"bigscape_families\"]\n",
    "                                            .map(family_to_sample_group)\n",
    "                                            .astype('Int64'))\n",
    "\n",
    "# display mibig_compounds_approved\n",
    "print(mibig_compounds_approved.head())"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Missing bigscape_families values present.\n",
      "        bgc_id  num_a_domains origins bigscape_families   compound_id  \\\n",
      "15  BGC0000296              6  mibig3          NRPS_277  BGC0000296.0   \n",
      "27  BGC0000305             11  mibig3  NRPS_285_mix_285  BGC0000305.0   \n",
      "28  BGC0000306              6  mibig3  NRPS_286_mix_286  BGC0000306.0   \n",
      "29  BGC0000307              9  mibig3  NRPS_287_mix_287  BGC0000307.0   \n",
      "34  BGC0000310             12  mibig3  NRPS_290_mix_290  BGC0000310.0   \n",
      "\n",
      "    num_recognized_nodes  iso_class_idx  in_approved_matches  sample_group  \n",
      "15                    11           3006                 True             3  \n",
      "27                    11           1782                 True             3  \n",
      "28                     6            368                 True             3  \n",
      "29                     9           3138                 True             3  \n",
      "34                    12            612                 True             3  \n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Form subsets of approved matches with MIBiG compounds for cross-validation.",
   "id": "d52c0d32b99d44b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T17:27:28.614163Z",
     "start_time": "2025-06-09T17:27:27.952558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import chain\n",
    "from src.matching.match_type import Match\n",
    "approved_matches_txt = Path(nerpa_dir / 'test_data/approved_matches/approved_matches.txt')\n",
    "approved_matches_strs = approved_matches_txt.read_text().split('\\n\\n')\n",
    "approved_matches = (Match.from_str(match_str)\n",
    "                    for match_str in approved_matches_strs\n",
    "                    if match_str.strip())\n",
    "approved_matches_per_compound = {match.nrp_variant_id.nrp_id: match\n",
    "                                 for match in approved_matches}\n",
    "\n",
    "benchmarking_dir = Path(nerpa_dir / 'benchmarking')\n",
    "(benchmarking_dir / 'approved_matches_subsets').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "subsets = mibig_compounds_approved.groupby('sample_group')['compound_id'].apply(list).to_dict()\n",
    "\n",
    "\"\"\"\n",
    "assert set(approved_matches_per_compound.keys()) == set(chain(*subsets.values())), \\\n",
    "    (\"The set of approved matches does not match the set of MIBiG compounds in subsets.\\n\"\n",
    "    f\"subsets \\ approved_matches = {set(chain(*subsets.values())) - set(approved_matches_per_compound.keys())}\\n\"\n",
    "    f\"approved_matches \\ subsets = {set(approved_matches_per_compound.keys()) - set(chain(*subsets.values()))}\")\n",
    "\"\"\"\n",
    "\n",
    "for group_idx, compound_ids in subsets.items():\n",
    "    testing_subset = [approved_matches_per_compound[nrp_id]\n",
    "                      for nrp_id in compound_ids]\n",
    "    training_subset = [match\n",
    "                       for match in approved_matches_per_compound.values()\n",
    "                       if match.nrp_variant_id.nrp_id not in compound_ids]\n",
    "\n",
    "    # Save the subset to a file\n",
    "    testing_subset_path = benchmarking_dir / 'approved_matches_subsets' / f'testing_subset_{group_idx}.txt'\n",
    "    training_subset_path = benchmarking_dir / 'approved_matches_subsets' / f'training_subset_{group_idx}.txt'\n",
    "    with open(testing_subset_path, 'w') as f:\n",
    "        f.write('\\n\\n'.join(map(str, testing_subset)))\n",
    "\n",
    "    with open(training_subset_path, 'w') as f:\n",
    "        f.write('\\n\\n'.join(map(str, training_subset)))"
   ],
   "id": "891581b93b6d2240",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
