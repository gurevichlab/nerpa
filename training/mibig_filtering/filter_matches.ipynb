{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "results_dir = Path('/home/ilya/tools/nerpa2/results/individual')\n",
    "\n",
    "all_matches = []\n",
    "for bgc_id in results_dir.iterdir():\n",
    "    matches_file = results_dir / Path(f'{bgc_id}/matches_details/matches.yaml')\n",
    "    if matches_file.exists():\n",
    "        matches_bgc = yaml.safe_load(matches_file.open())\n",
    "        all_matches.extend(matches_bgc)\n",
    "    else:\n",
    "        print('No output for', bgc_id)\n",
    "\n",
    "\n",
    "def write_yaml(data, out_file: Path,\n",
    "               compress: bool = False):\n",
    "    # dirty hack to erase information about types and make output less verbose\n",
    "    # https://github.com/yaml/pyyaml/issues/408\n",
    "    yaml.emitter.Emitter.prepare_tag = lambda self, tag: ''\n",
    "\n",
    "    # another hack (albeit less dirty) to forbid yaml creating references\n",
    "    # https://stackoverflow.com/questions/13518819/avoid-references-in-pyyaml\n",
    "    if not compress:\n",
    "        yaml.Dumper.ignore_aliases = lambda *args: True\n",
    "\n",
    "    with open(out_file, 'w') as out:\n",
    "        yaml.dump(data, out,\n",
    "                  default_flow_style=None, sort_keys=False)\n",
    "\n",
    "\n",
    "write_yaml(all_matches, Path('all_matches.yaml'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b696c3a503058448"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for local run\n",
    "import yaml\n",
    "all_matches = yaml.safe_load(open('/home/ilianolhin/git/nerpa2/training/mibig_filtering/all_matches.yaml'))"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-25T18:05:43.047980516Z",
     "start_time": "2024-05-25T18:05:28.704731680Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matches: \n",
      "2265\n",
      "Best score: \n",
      "-0.2568675308800029\n",
      "Worst score: \n",
      "-8.924415040391763\n"
     ]
    }
   ],
   "source": [
    "all_matches.sort(key=lambda match: match['NormalisedScore'], reverse=True)\n",
    "print('Total number of matches: ')\n",
    "print(len(all_matches)) \n",
    "print('Best score: ')\n",
    "print(all_matches[0]['NormalisedScore'])\n",
    "print('Worst score: ')\n",
    "print(all_matches[-1]['NormalisedScore'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T18:05:43.058107462Z",
     "start_time": "2024-05-25T18:05:43.049953074Z"
    }
   },
   "id": "8e6a338ac8a7ad5a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def show_match(match: dict) -> str:\n",
    "    result = ''\n",
    "    result += f\"Genome: {match['Genome']}\\n\"\n",
    "    result += f\"BGC_variant_idx: {match['BGC_variant_idx']}\\n\"\n",
    "    result += f\"NRP: {match['NRP']}\\n\"\n",
    "    result += f\"NRP_variant_idx: {match['NRP_variant_idx']}\\n\"\n",
    "    result += f\"NormalisedScore: {match['NormalisedScore']}\\n\"\n",
    "    result += f\"Score: {match['Score']}\\n\"\n",
    "    result += f\"Alignment:\\n\"\n",
    "    for i, alignment in enumerate(match['Alignments']):\n",
    "        if len(match['Alignments']) > 1:\n",
    "            result += f'Fragment_{i}\\n'\n",
    "        t = PrettyTable(alignment[0].keys(), align='l', border=False)\n",
    "        t.add_rows(alignment_step.values() for alignment_step in alignment)\n",
    "        result += str(t) + '\\n'\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T18:05:43.067883110Z",
     "start_time": "2024-05-25T18:05:43.053158306Z"
    }
   },
   "id": "b8fe62d2468607ef",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of BGCs 288\n",
      "Total number of NRPs\n",
      "511\n",
      "Total number of non-iterative NRPs: \n",
      "458\n",
      "Total number of matches for iterative NRPs: \n",
      "637\n"
     ]
    }
   ],
   "source": [
    "# q: group matches by NRP\n",
    "from collections import defaultdict\n",
    "nrp_matches = defaultdict(list)\n",
    "for match in all_matches:\n",
    "    nrp_matches[match['NRP']].append(match)\n",
    "\n",
    "nrp_noniterative_matches = {}\n",
    "nrp_iterative_matches = {}\n",
    "for nrp, matches in nrp_matches.items():\n",
    "    if any(len(match['Alignments']) > 1 for match in matches):\n",
    "        nrp_iterative_matches[nrp] = matches\n",
    "    else:\n",
    "        nrp_noniterative_matches[nrp] = max(matches, key=lambda match: match['NormalisedScore'])\n",
    "\n",
    "print('Total number of BGCs', len(set(match['NRP'].split('.')[0] for match in all_matches)))\n",
    "print('Total number of NRPs')\n",
    "print(len(nrp_matches.keys()))\n",
    "print('Total number of non-iterative NRPs: ')\n",
    "print(len(nrp_noniterative_matches))\n",
    "print('Total number of matches for iterative NRPs: ')\n",
    "print(sum(len(matches) for matches in nrp_iterative_matches.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T18:05:43.086881874Z",
     "start_time": "2024-05-25T18:05:43.068550916Z"
    }
   },
   "id": "7a9425a973588973",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-iterative matches for inspection: \n",
      "246\n",
      "Total number of good non-iterative matches: \n",
      "90\n"
     ]
    }
   ],
   "source": [
    "def num_skips(alignment):\n",
    "    return sum(1 for alignment_step in alignment\n",
    "               if alignment_step['Alignment_step'] == 'NRP_MONOMER_SKIP'\n",
    "               or alignment_step['Alignment_step'] == 'BGC_MODULE_SKIP')\n",
    "\n",
    "def num_monomers(alignment):\n",
    "    return sum(1 for alignment_step in alignment\n",
    "               if alignment_step['Alignment_step'] == 'NRP_MONOMER_SKIP'\n",
    "               or alignment_step['Alignment_step'] == 'MATCH')\n",
    "\n",
    "def num_modules(alignment):\n",
    "    return sum(1 for alignment_step in alignment\n",
    "               if alignment_step['Alignment_step'] == 'MATCH'\n",
    "               or alignment_step['Alignment_step'] == 'BGC_MODULE_SKIP')\n",
    "    \n",
    "def good_alignment(alignment):\n",
    "    return all(step['Alignment_step'] == 'MATCH' and step['NRP_residue'] in step['Top_scoring_residues']\n",
    "               for step in alignment)\n",
    "        \n",
    "noniterative_matches_for_inspection = []\n",
    "good_noniterative_matches = []\n",
    "for match in nrp_noniterative_matches.values():\n",
    "    alignment = match['Alignments'][0]\n",
    "    if not all([match['NormalisedScore'] > -4,\n",
    "                num_skips(alignment) <= 4,\n",
    "                num_monomers(alignment) >= 3,\n",
    "                num_modules(alignment) >= 3]):\n",
    "        continue\n",
    "    if good_alignment(alignment):\n",
    "        good_noniterative_matches.append(match)\n",
    "    else:\n",
    "        noniterative_matches_for_inspection.append(match)\n",
    "\n",
    "print('Total number of non-iterative matches for inspection: ')\n",
    "print(len(noniterative_matches_for_inspection))\n",
    "print('Total number of good non-iterative matches: ')\n",
    "print(len(good_noniterative_matches))\n",
    "\n",
    "with open('/home/ilianolhin/git/nerpa2/training/mibig_filtering/noniterative_matches_for_inspection.txt', 'w') as out:\n",
    "    for match in noniterative_matches_for_inspection:\n",
    "        out.write(show_match(match) + '\\n\\n')\n",
    "\n",
    "with open('/home/ilianolhin/git/nerpa2/training/mibig_filtering/good_noniterative_matches.txt', 'w') as out:\n",
    "    for match in good_noniterative_matches:\n",
    "        out.write(show_match(match) + '\\n\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T18:21:58.486064082Z",
     "start_time": "2024-05-25T18:21:58.119804666Z"
    }
   },
   "id": "933444b0afc22a75",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of iterative matches for inspection: \n",
      "95\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "from itertools import chain\n",
    "\n",
    "def get_monomers(match) -> List[Tuple[str, str, str]]:\n",
    "    monomers = []\n",
    "    for alignment in match['Alignments']:\n",
    "        for alignment_step in alignment:\n",
    "            if alignment_step['Alignment_step'] == 'MATCH' or alignment_step['Alignment_step'] == 'NRP_MONOMER_SKIP':\n",
    "                monomers.append((alignment_step['rBAN_name'], alignment_step['NRP_chirality']))\n",
    "    return monomers\n",
    "\n",
    "def get_modules(match) -> List[str]:\n",
    "    modules = []\n",
    "    for alignment in match['Alignments']:\n",
    "        for alignment_step in alignment:\n",
    "            if alignment_step['Alignment_step'] == 'MATCH' or alignment_step['Alignment_step'] == 'BGC_MODULE_SKIP':\n",
    "                modules.append((alignment_step['Gene'], alignment_step['A-domain_idx']))\n",
    "    return modules\n",
    "\n",
    "iterative_matches_for_inspection = []\n",
    "for nrp, matches in nrp_iterative_matches.items():\n",
    "    max_len = max(len(get_monomers(match)) for match in matches)  # max len means permutations of fragments\n",
    "    best_score_max_len = max(match['NormalisedScore'] for match in matches if len(get_monomers(match)) == max_len)  # best permutation\n",
    "    seen_variants = [] \n",
    "    for match in matches:\n",
    "        monomers = get_monomers(match)\n",
    "        modules = get_modules(match)\n",
    "        if len(match['Alignments']) > 1:\n",
    "            continue\n",
    "        alignment = match['Alignments'][0]\n",
    "        if any([match['NormalisedScore'] < -4,\n",
    "                num_skips(alignment)  >= min(5, min(num_modules(alignment), num_monomers(alignment))),\n",
    "                len(monomers) == max_len and match['NormalisedScore'] < best_score_max_len,  # not the best permutation\n",
    "                (modules, monomers) in seen_variants]):\n",
    "            continue\n",
    "        seen_variants.append((modules, monomers))\n",
    "        iterative_matches_for_inspection.append(match)\n",
    "\n",
    "print('Total number of iterative matches for inspection: ')\n",
    "print(len(iterative_matches_for_inspection))\n",
    "\n",
    "with open('/home/ilianolhin/git/nerpa2/training/mibig_filtering/iterative_matches_for_inspection.txt', 'w') as out:\n",
    "    for match in iterative_matches_for_inspection:\n",
    "        out.write(show_match(match) + '\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T18:28:20.042215406Z",
     "start_time": "2024-05-25T18:28:19.952942214Z"
    }
   },
   "id": "e51bdce4266482ed",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb56401915a9975c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
